// Tests for the self-hosted Zen lexer

comptime {
    lexer := @std.lexer
    io := @std.io
}

// Test basic tokenization
test_basic_tokens = () bool {
    input := "x := 42"
    lex := lexer::lexer_new(input)
    
    // First token: identifier "x"
    result := lexer::lexer_next_token(lex)
    lex = result.0
    token := result.1
    
    token.token_type ?
        | Identifier(name) => {
            string_equals(name, "x") ? 
                | false => return false
        }
        | _ => return false
    
    // Second token: operator ":="
    result = lexer::lexer_next_token(lex)
    lex = result.0
    token = result.1
    
    token.token_type ?
        | Operator(op) => {
            string_equals(op, ":=") ?
                | false => return false
        }
        | _ => return false
    
    // Third token: integer "42"
    result = lexer::lexer_next_token(lex)
    lex = result.0
    token = result.1
    
    token.token_type ?
        | Integer(num) => {
            string_equals(num, "42") ?
                | false => return false
        }
        | _ => return false
    
    // Fourth token: EOF
    result = lexer::lexer_next_token(lex)
    token = result.1
    
    token.token_type ?
        | Eof => {}
        | _ => return false
    
    return true
}

// Test keywords
test_keywords = () bool {
    keywords := ["loop", "in", "comptime", "return", "break", "continue", "true", "false"]
    
    loop kw in keywords {
        lex := lexer::lexer_new(kw)
        result := lexer::lexer_next_token(lex)
        token := result.1
        
        token.token_type ?
            | Keyword(_) => {}
            | _ => return false
    }
    
    return true
}

// Test operators
test_operators = () bool {
    operators := [":=", "::=", "::", "==", "!=", "<=", ">=", "&&", "||", "->", "=>", "..", "..=", "<<", ">>"]
    
    loop op in operators {
        lex := lexer::lexer_new(op)
        result := lexer::lexer_next_token(lex)
        token := result.1
        
        token.token_type ?
            | Operator(parsed_op) => {
                string_equals(parsed_op, op) ?
                    | false => {
                        printf("Failed: expected '%s', got '%s'\n", op, parsed_op)
                        return false
                    }
            }
            | _ => {
                printf("Failed: '%s' not parsed as operator\n", op)
                return false
            }
    }
    
    return true
}

// Test string literals
test_strings = () bool {
    // Simple string
    lex := lexer::lexer_new("\"hello world\"")
    result := lexer::lexer_next_token(lex)
    token := result.1
    
    token.token_type ?
        | StringLiteral(s) => {
            string_equals(s, "hello world") ?
                | false => return false
        }
        | _ => return false
    
    // String with escape
    lex = lexer::lexer_new("\"hello\\nworld\"")
    result = lexer::lexer_next_token(lex)
    token = result.1
    
    token.token_type ?
        | StringLiteral(_) => {}
        | _ => return false
    
    return true
}

// Test numbers
test_numbers = () bool {
    // Integer
    lex := lexer::lexer_new("123")
    result := lexer::lexer_next_token(lex)
    token := result.1
    
    token.token_type ?
        | Integer(n) => {
            string_equals(n, "123") ?
                | false => return false
        }
        | _ => return false
    
    // Float
    lex = lexer::lexer_new("123.456")
    result = lexer::lexer_next_token(lex)
    token = result.1
    
    token.token_type ?
        | Float(f) => {
            string_equals(f, "123.456") ?
                | false => return false
        }
        | _ => return false
    
    // Hex
    lex = lexer::lexer_new("0xFF")
    result = lexer::lexer_next_token(lex)
    token = result.1
    
    token.token_type ?
        | Integer(h) => {
            string_equals(h, "0xFF") ?
                | false => return false
        }
        | _ => return false
    
    // Type suffix
    lex = lexer::lexer_new("42i32")
    result = lexer::lexer_next_token(lex)
    token = result.1
    
    token.token_type ?
        | Integer(n) => {
            string_equals(n, "42i32") ?
                | false => return false
        }
        | _ => return false
    
    return true
}

// Test comments
test_comments = () bool {
    // Line comment
    lex := lexer::lexer_new("// this is a comment")
    result := lexer::lexer_next_token(lex)
    token := result.1
    
    token.token_type ?
        | Comment(c) => {
            string_equals(c, " this is a comment") ?
                | false => return false
        }
        | _ => return false
    
    // Block comment
    lex = lexer::lexer_new("/* multi\nline */")
    result = lexer::lexer_next_token(lex)
    token = result.1
    
    token.token_type ?
        | Comment(_) => {}
        | _ => return false
    
    return true
}

// Test symbols
test_symbols = () bool {
    symbols := "(){}[];,|&.?"
    lex := lexer::lexer_new(symbols)
    
    i ::= 0
    loop i < string_len(symbols) {
        result := lexer::lexer_next_token(lex)
        lex = result.0
        token := result.1
        i = i + 1
        
        token.token_type ?
            | Symbol(_) => {}
            | Eof => break
            | _ => return false
    }
    
    return true
}

// Test namespace identifiers
test_namespaces = () bool {
    lex := lexer::lexer_new("@std.core.vec")
    result := lexer::lexer_next_token(lex)
    token := result.1
    
    token.token_type ?
        | Identifier(name) => {
            string_equals(name, "@std.core.vec") ?
                | false => return false
        }
        | _ => return false
    
    return true
}

// Test position tracking
test_positions = () bool {
    input := "x\n  y"
    lex := lexer::lexer_new(input)
    
    // First token on line 1, column 1
    result := lexer::lexer_next_token(lex)
    lex = result.0
    token := result.1
    
    token.line == 1 && token.column == 1 ?
        | false => return false
    
    // Second token on line 2, column 3 (after 2 spaces)
    result = lexer::lexer_next_token(lex)
    token = result.1
    
    token.line == 2 && token.column == 3 ?
        | false => return false
    
    return true
}

// Test complete tokenization
test_tokenize_all = () bool {
    input := "x := 42 + y"
    tokens := lexer::lexer_tokenize_all(input)
    
    vec_len(&tokens) == 6 ?  // x, :=, 42, +, y, EOF
        | false => return false
    
    // Check last token is EOF
    last := vec_get(&tokens, vec_len(&tokens) - 1)
    last ?
        | Some(token) => {
            token.token_type ?
                | Eof => {}
                | _ => return false
        }
        | None => return false
    
    return true
}

// Test complex code
test_complex_code = () bool {
    code := "
Vec<T> = {
    data: *T,
    len: i64,
}

vec_push<T> = (vec: *Vec<T>, item: T) void {
    vec.len >= vec.capacity ?
        | true => vec_grow(vec)
        | false => {}
    
    vec.data[vec.len] = item
    vec.len = vec.len + 1
}
"
    
    tokens := lexer::lexer_tokenize_all(code)
    
    // Should have many tokens
    vec_len(&tokens) > 50 ?
        | false => return false
    
    // Should contain specific tokens
    has_vec := false
    has_generic := false
    has_pattern := false
    
    i ::= 0
    loop i < vec_len(&tokens) {
        token_opt := vec_get(&tokens, i)
        i = i + 1
        token_opt ?
            | Some(token) => {
                token.token_type ?
                    | Identifier(name) => {
                        string_equals(name, "Vec") ? | true => { has_vec = true }
                        string_equals(name, "T") ? | true => { has_generic = true }
                    }
                    | Symbol(63) => { has_pattern = true }  // '?'
                    | _ => {}
            }
            | None => {}
    }
    
    has_vec && has_generic && has_pattern ?
        | false => return false
    
    return true
}

// Run all tests
main = () i32 {
    printf("Testing self-hosted Zen lexer...\n")
    
    test_basic_tokens() ? 
        | true => printf("✓ Basic tokens\n")
        | false => {
            printf("✗ Basic tokens FAILED\n")
            return 1
        }
    
    test_keywords() ?
        | true => printf("✓ Keywords\n")
        | false => {
            printf("✗ Keywords FAILED\n")
            return 1
        }
    
    test_operators() ?
        | true => printf("✓ Operators\n")
        | false => {
            printf("✗ Operators FAILED\n")
            return 1
        }
    
    test_strings() ?
        | true => printf("✓ String literals\n")
        | false => {
            printf("✗ String literals FAILED\n")
            return 1
        }
    
    test_numbers() ?
        | true => printf("✓ Numbers\n")
        | false => {
            printf("✗ Numbers FAILED\n")
            return 1
        }
    
    test_comments() ?
        | true => printf("✓ Comments\n")
        | false => {
            printf("✗ Comments FAILED\n")
            return 1
        }
    
    test_symbols() ?
        | true => printf("✓ Symbols\n")
        | false => {
            printf("✗ Symbols FAILED\n")
            return 1
        }
    
    test_namespaces() ?
        | true => printf("✓ Namespace identifiers\n")
        | false => {
            printf("✗ Namespace identifiers FAILED\n")
            return 1
        }
    
    test_positions() ?
        | true => printf("✓ Position tracking\n")
        | false => {
            printf("✗ Position tracking FAILED\n")
            return 1
        }
    
    test_tokenize_all() ?
        | true => printf("✓ Tokenize all\n")
        | false => {
            printf("✗ Tokenize all FAILED\n")
            return 1
        }
    
    test_complex_code() ?
        | true => printf("✓ Complex code\n")
        | false => {
            printf("✗ Complex code FAILED\n")
            return 1
        }
    
    printf("\nAll lexer tests passed! 🎉\n")
    return 0
}

// Helper functions that would be in string module
extern string_len = (string) i32
extern string_char_at = (string, i32) i8
extern string_substring = (string, i32, i32) string
extern string_equals = (string, string) bool
extern printf = (*i8, ...) i32